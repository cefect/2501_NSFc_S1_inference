# inference submit file

STAGING_DIR = staging/sbryant8/2501_NSFc/s1_infer/
INPUT_DIR = Example_img
JOBID_BASE = $(Cluster)_$(SUBMIT_TIME)
OUTDIR = $(JOBID_BASE)_out
CKPT_PATH = epoch-13-val_f1-0.0000_weights.ckpt


#set the image
universe = container
container_image = docker://cefect/pytorch-2.6.0-cuda12.4_terratorch:v0
 

# Your job's launcher script (transferred and executed inside the container)
executable      = htcondor/run.sh

# We will pass *relative* paths that exist in the job's working directory
# after HTCondor unpacks the staged tarball (see transfer_input_files below).
#    args: input_dir             ckpt_path                                          output_dir
arguments       = $(INPUT_DIR) $(CKPT_PATH) $(OUTDIR)


# --- file transfer (required for Docker/containers) ---
should_transfer_files   = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
preserve_relative_paths = True

# Ship code, input images (as a tarball that is auto-unpacked), and model checkpoint
transfer_input_files = src, \
    osdf:///chtc/$(STAGING_DIR)/$(INPUT_DIR).tar.gz?pack=auto, \
    osdf:///chtc/$(STAGING_DIR)/$(CKPT_PATH)




# Explicitly pull back the program output (top-level file)
requirements = (HasCHTCStaging == true)
transfer_output_files = $(OUTDIR)

#specifies both a plug-in and a destination for the transfer of the entire output sandbox or a subset of output files as specified by the submit command transfer_output_files
#must be a plugin (not a path)
output_destination = osdf:///chtc/$(STAGING_DIR)/output/

# --- logs on the SUBMIT node (your /home) ---
LOG_BASE = htcondor/logs/$(JOBID_BASE)

output = $(LOG_BASE).out
error  = $(LOG_BASE).err
log    = $(LOG_BASE).htc-log

stream_output = False
stream_error  = False

 


# Resources (tune as needed)
request_cpus   = 1
request_memory = 10GB
request_disk   = 10GB

# GPU
request_gpus = 1
#gpus_minimum_capability = 7.5
gpus_minimum_runtime = 12.4
#mininum quantity of GPU memory in MiB
gpus_minimum_memory = 200MB 
#+WantGPULab = true
+GPUJobLength = "short"

 
queue
